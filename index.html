<!DOCTYPE html>
<html>

<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Hao Yang's Web Page">
    <meta name="keywords" content="vision,graphics,research,deep learning,neural network">
    <meta property="og:title" content="Hao Yang | 杨昊">
    <meta property="og:description" content="Hao Yang's Web Page">
    <meta property="og:image" content="images/wechat.jpg">
    <title>Hao Yang | 杨昊</title>
    <link rel="stylesheet" href="css/common.css" type="text/css" />
</head>


<body>
    <div id="narrow-content">
        <div class="banner">
            <ul>
                <li>Hao Yang | 杨昊</li>
                <li><a href="http://scr.im/haya">Email</a></li>
                <li><a href="https://www.linkedin.com/in/haoyang-msra/">LinkedIn</a></li>
            </ul>
        </div>
        <div class="info">
            <div class="portrait">
                <img src="images/wechat.jpg" />
            </div>
            <div class="introduction">
                I joined the Visual Computing Group of Microsoft Research Asia in late 2017.

                Before that, I received both my B.S and PhD degrees from the School of Software, Tsinghua University.
                My research interests include but are not limited to the understanding and synthesis of faces and 3D.
            </div>
        </div>

        <div class="block">
            <h3>Selected Publications</h3>
            <ul>
                <li>Lingzhi Li, Jianmin Bao, <strong>Hao Yang</strong>, Dong Chen, Fang Wen,
                    <strong>FaceShifter: Towards High Fidelity And Occlusion Aware Face Swapping</strong>.
                    Computer Vision and Pattern Recognition 2020 (oral).
                    <a href="https://arxiv.org/pdf/1912.13457.pdf">[paper]</a>
                </li>
                <li>Lingzhi Li, Jianmin Bao, Ting Zhang, <strong>Hao Yang</strong>, Dong Chen, Fang Wen, Baining Guo,
                    <strong>Face X-ray for More General Face Forgery Detection</strong>.
                    Computer Vision and Pattern Recognition 2020 (oral).
                    <a href="https://arxiv.org/pdf/1912.13458.pdf">[paper]</a>
                </li>
                <li>Jinpeng Lin, <strong>Hao Yang</strong>, Dong Chen, Ming Zeng, Fang Wen, Lu Yuan,
                    <strong>Face Parsing with RoI Tanh-warping</strong>.
                    Computer Vision and Pattern Recognition 2019.
                    <a href="https://arxiv.org/pdf/1906.01342.pdf">[paper]</a>
                    <a href="https://github.com/JPlin/Relabeled-HELEN-Dataset">[data]</a>
                </li>
                <li>Shuyang Gu, Jianmin Bao, <strong>Hao Yang</strong>, Dong Chen, Fang Wen, Lu Yuan,
                    <strong>Mask-Guided Portrait Editing with Conditional GANs</strong>.
                    Computer Vision and Pattern Recognition 2019.
                    <a href="https://arxiv.org/pdf/1905.10346.pdf">[paper]</a>
                </li>
                <li><strong>Hao Yang</strong> and Hui Zhang,
                    <strong>Automatic 3D reconstruction of a polyhedral object from a single line drawing under
                        perspective projection</strong>.
                    Computers & Graphics 65 (2017): 45-59.
                    <a href="https://doi.org/10.1016/j.cag.2017.04.003">[paper]</a>
                </li>
                <li><strong>Hao Yang</strong> and Hui Zhang, <strong>Efficient 3D Room Shape Recovery from a Single
                        Panorama</strong>.
                    Computer Vision and Pattern Recognition 2016 (full oral).
                    <a href="http://cgcad.thss.tsinghua.edu.cn/yanghao/3droom/index.html">[project]</a>
                </li>
                <li>Yunfeng Liang, <strong>Hao Yang</strong>, and Hui Zhang.
                    <strong>A Per-pixel Noise Detection Approach for Example-Based Photometric Stereo</strong>.
                    Computers & Graphics 46 (2015): 327-335.
                    <a href="http://dl.acm.org/citation.cfm?id=2802437">[paper]</a>
                </li>
            </ul>
        </div>
    </div>
</body>

</html>